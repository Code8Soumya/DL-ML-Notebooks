{"cells":[{"cell_type":"markdown","metadata":{"id":"zF3DoHOh9Soo"},"source":["# CNN"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Klg90ox34NoB"},"outputs":[],"source":["from google.colab import drive\n","drive.mount(\"/content/drive\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Mg1nzA23_WJJ"},"outputs":[],"source":["# %cd /content/drive/MyDrive"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"x9g8vEJ5lqA6"},"outputs":[],"source":["# !pip install -q kaggle\n","# from google.colab import files\n","# files.upload()\n","# !mkdir ~/.kaggle\n","# !cp kaggle.json ~/.kaggle/\n","# !chmod 600 ~/.kaggle/kaggle.json"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lmT-WH-MODpS"},"outputs":[],"source":["# !cat ~/.kaggle/kaggle.json"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uc-9GnJ9taFi"},"outputs":[],"source":["# !kaggle competitions files UBC-OCEAN"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tNhOyHA34yWG"},"outputs":[],"source":["# !kaggle competitions download -c UBC-OCEAN -f train.csv -p /content/drive/MyDrive/Data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TXA433mc5jj5"},"outputs":[],"source":["# image_id_array = np.array(df[\"image_id\"])\n","# competition = \"UBC-OCEAN\"\n","# download_path = \"/content/training_files_zipped\"\n","# for i in image_id_array:\n","#     download_command = f\"kaggle competitions download -c {competition} -f train_thumbnails/{i}_thumbnail.png -p {download_path}\"\n","#     !download_command"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TdfHYiklXSDT"},"outputs":[],"source":["!pip install keras-cv"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GepEqtjRRsgi"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import tensorflow as tf\n","from tensorflow import keras\n","import seaborn as sns\n","from keras import regularizers\n","from PIL import Image\n","from numpy import asarray\n","from keras import layers\n","from keras.layers import Conv2D\n","import pickle\n","import os\n","\n","os.environ[\"KERAS_BACKEND\"] = \"jax\"\n","import keras_cv\n","\n","sns.set(style=\"whitegrid\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zxa3NYuSmrgr"},"outputs":[],"source":["# gpus = tf.config.list_physical_devices('GPU')\n","# if gpus:\n","#   # Restrict TensorFlow to only allocate 10GB of memory on the first GPU\n","#   try:\n","#     tf.config.set_logical_device_configuration(\n","#         gpus[0],\n","#         [tf.config.LogicalDeviceConfiguration(memory_limit=10240)])\n","#     logical_gpus = tf.config.list_logical_devices('GPU')\n","#     print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n","#   except RuntimeError as e:\n","#     # Virtual devices must be set before GPUs have been initialized\n","#     print(e)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HP05d7RhuY8o"},"outputs":[],"source":["# !lscpu |grep 'Model name'"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9NC50cVLqzu0"},"outputs":[],"source":["# cpus = tf.config.list_physical_devices('CPU')\n","# if cpus:\n","#   # Restrict TensorFlow to only allocate 8GB of memory on the first CPU\n","#   try:\n","#     tf.config.set_logical_device_configuration(\n","#         cpus[0],\n","#         [tf.config.LogicalDeviceConfiguration(memory_limit=8192)])\n","#     logical_cpus = tf.config.list_logical_devices('CPU')\n","#     print(len(cpus), \"Physical CPUs,\", len(logical_cpus), \"Logical CPUs\")\n","#   except RuntimeError as e:\n","#     # Virtual devices must be set before CPUs have been initialized\n","#     print(e)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MMwyw4QuDUoA"},"outputs":[],"source":["class Config:\n","    is_submission = False\n","\n","    train_csv_path = \"/content/drive/MyDrive/train.csv\"\n","    train_data_paths = \"/content/drive/MyDrive/Training_files\"\n","    batch_size = 16\n","    epochs = 30\n","\n","    test_csv_path = \"/content/drive/MyDrive/test.csv\"\n","    test_data_paths = \"/content/drive/MyDrive/Testing_files\"\n","\n","config = Config()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vHVqpEHP1r9Z"},"outputs":[],"source":["# img = Image.open(\"/content/drive/MyDrive/Training_files/10077_thumbnail.png\")\n","# numpydata = asarray(img)\n","\n","# print(type(numpydata))\n","# print(numpydata.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LTc83cve9u34"},"outputs":[],"source":["df = pd.read_csv(\"/content/drive/MyDrive/train.csv\")\n","\n","df = df[df[\"is_tma\"] == False]\n","\n","num_rows = df.shape[0]\n","num_unique_images = df['image_id'].nunique()\n","num_unique_labels = df['label'].nunique()\n","unique_labels = df['label'].unique()\n","\n","print(f\"{num_rows=}\")\n","print(f\"{num_unique_images=}\")\n","print(f\"{num_unique_labels=}\")\n","print(f\"{unique_labels=}\")\n","\n","plt.figure(figsize=(10, 6))\n","sns.countplot(data=df, x='label', order=df['label'].value_counts().index)\n","plt.title('Distribution of Target Classes')\n","plt.xlabel('Label')\n","plt.ylabel('Count')\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gWO6lMT1CLTs"},"outputs":[],"source":["df.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"k3PJCCe_xVim"},"outputs":[],"source":["df.describe()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hA-YZ0RHxVcX"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"js0vHlQfxVUM"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kD3xFSqlBPdW"},"outputs":[],"source":["if not config.is_submission:\n","    # Perform one-hot encoding of the 'label' column and explicitly convert to integer type\n","    df_one_hot = pd.get_dummies(df[\"label\"], prefix=\"label\").astype(int)\n","\n","    # Concatenate the original DataFrame with the one-hot encoded labels\n","    train_df = pd.concat([df[\"image_id\"], df_one_hot], axis=1)\n","\n","    # Get the thumbnail image paths\n","    train_df[\"train_image_path\"] = train_df[\"image_id\"].apply(lambda x: f\"{config.train_data_paths}/{x}_thumbnail.png\")\n","\n","    train_image_paths = train_df[\"train_image_path\"].values\n","    labels = train_df[[col for col in train_df.columns if col.startswith(\"label_\")]].values\n","\n","    label_names = [col for col in train_df.columns if col.startswith(\"label_\")]\n","    name_to_id = {key.replace(\"label_\", \"\"):value for value,key in enumerate(label_names)}\n","    id_to_name = {key:value for value, key in name_to_id.items()}\n","\n","    # Save to dictionary to disk\n","    with open(\"id_to_name.pkl\", \"wb\") as f:\n","        pickle.dump(id_to_name, f)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UZ5GQbddmDK4"},"outputs":[],"source":["train_df.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"58TkilC417iU"},"outputs":[],"source":["def read_image(path):\n","    file = tf.io.read_file(path)\n","    image = tf.io.decode_png(file, 0)\n","    image = tf.image.resize(image, (300, 300), antialias=True)\n","    image = tf.image.per_image_standardization(image)\n","    return image"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uPv7Zktb2Gq2"},"outputs":[],"source":["read_image(\"/content/drive/MyDrive/Training_files/10077_thumbnail.png\").shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uaPiPM4V1avH"},"outputs":[],"source":["data_augmentation = tf.keras.Sequential([\n","    layers.RandomFlip(\"horizontal_and_vertical\"),\n","    layers.RandomRotation(0.25),\n","  ])\n","\n","def image_augmenter(path):\n","    file = tf.io.read_file(path)\n","    image = tf.io.decode_png(file, 0)\n","    image = tf.image.resize(image, (300, 300), antialias=True)\n","    image = data_augmentation(image)\n","    image = tf.image.per_image_standardization(image)\n","    return image"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"v2rPutKEqEgt"},"outputs":[],"source":["image_augmenter(\"/content/drive/MyDrive/Training_files/10077_thumbnail.png\").shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NQnprrxe1sjd"},"outputs":[],"source":["# plt.figure(figsize=(10, 10))\n","# for i in range(4):\n","#   augmented_image = image_augmenter(\"/content/drive/MyDrive/Training_files/10077_thumbnail.png\")\n","#   ax = plt.subplot(2, 2, i + 1)\n","#   plt.imshow(augmented_image[0])\n","#   plt.axis(\"off\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6MzQKloZPcjJ"},"outputs":[],"source":["# if not config.is_submission:\n","#     class_weights = np.sum(labels) - np.sum(labels, axis=0)\n","#     class_weights = class_weights / np.sum(class_weights) # Normalize the weights\n","\n","#     class_weights = {idx:weight for idx, weight in enumerate(class_weights)}\n","\n","#     for idx, weight in class_weights.items():\n","#         print(f\"{id_to_name[idx]}: {weight:0.2f}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jv-ma6iJ152z"},"outputs":[],"source":["label_names"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rEdaciB4SsDo"},"outputs":[],"source":["sample_of_each_image_required = 300\n","required_augmented_image_dict = {}\n","intermediate_dict = dict(sample_of_each_image_required - df[\"label\"].value_counts())\n","\n","for i in [key.replace(\"label_\", \"\") for key in label_names]:\n","    required_augmented_image_dict.update({i:intermediate_dict[i]})\n","\n","print(required_augmented_image_dict)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JLTo2BhmRUhg"},"outputs":[],"source":["# def augmented_image_generator(dictionary):\n","#     for k,v in dictionary.items():\n","#         lst = list(train_df[train_df[f\"label_{k}\"] == 1].sample(v, replace=True)[\"train_image_path\"])\n","#         tensor = tf.concat([tf.image.per_image_standardization(data_augmentation(read_image(i)))[tf.newaxis,...] for i in lst],0)\n","#         data = tf.data.Dataset.from_tensors(tensor)\n","#         data.save(f\"/content/augmented_datasets/{k}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BJGm-YrejNe4"},"outputs":[],"source":["def images_for_augmentation_paths_generator(dictionary):\n","    lst_main = []\n","    for k,v in dictionary.items():\n","        lst = list(train_df[train_df[f\"label_{k}\"] == 1].sample(v, replace=True)[\"train_image_path\"])\n","        lst_main.extend(lst)\n","    return lst_main"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HpxIzd96j0Op"},"outputs":[],"source":["augmented_images_paths_list = images_for_augmentation_paths_generator(required_augmented_image_dict)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ue8vIjJYdq5e"},"outputs":[],"source":["# def augmented_image_generator(location):\n","#     data = tf.image.per_image_standardization(data_augmentation(read_image(location)))\n","#     return data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"l9NQ_6QX-cwJ"},"outputs":[],"source":["augmented_images_labels = []\n","for i in augmented_images_paths_list:\n","    new_df = train_df[train_df[\"train_image_path\"] == i]\n","    new_label = list(new_df[[col for col in new_df.columns if col.startswith(\"label_\")]].values[0])\n","    augmented_images_labels.append(new_label)\n","\n","augmented_images_labels_array = np.array(augmented_images_labels)\n","labels_final = np.concatenate((labels, augmented_images_labels_array), 0)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bqEKANaIRUfK"},"outputs":[],"source":["if not config.is_submission:\n","    x1 = (tf.data.Dataset.from_tensor_slices(train_image_paths).map(image_augmenter, num_parallel_calls=tf.data.AUTOTUNE, deterministic=True)\n","                                                               .cache(\"Cached_data_x1\")\n","                                                               .prefetch(buffer_size=tf.data.AUTOTUNE)\n","          )\n","    x2 = (tf.data.Dataset.from_tensor_slices(augmented_images_paths_list).map(image_augmenter, num_parallel_calls=tf.data.AUTOTUNE, deterministic=True)\n","                                                                         .cache(\"Cached_data_x2\")\n","                                                                         .prefetch(buffer_size=tf.data.AUTOTUNE)\n","          )\n","    x = tf.data.Dataset.concatenate(x1, x2)\n","    y = tf.data.Dataset.from_tensor_slices(labels_final)\n","\n","    # Zip the x and y together\n","    ds = tf.data.Dataset.zip((x, y))\n","    ds_final = (\n","        ds\n","        .shuffle(buffer_size=200)\n","        .cache(\"Cached_data_ds\")\n","        .prefetch(buffer_size=tf.data.AUTOTUNE)\n","    )\n","    # Create the training and validation splits\n","    val_ds = (\n","        ds_final\n","        .take(200)\n","        .shuffle(100)\n","        .batch(config.batch_size)\n","        .cache(\"Cached_data_val_ds\")\n","        .prefetch(tf.data.AUTOTUNE)\n","    )\n","    train_ds = (\n","        ds_final\n","        .skip(200)\n","        .shuffle(100)\n","        .batch(config.batch_size)\n","        .cache(\"Cached_data_train_ds\")\n","        .prefetch(tf.data.AUTOTUNE)\n","    )"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Z0W4r5uORUcs"},"outputs":[],"source":["# if not config.is_submission:\n","#     images, labels = train_ds.take(1).get_single_element()\n","\n","#     keras_cv.visualization.plot_image_gallery(\n","#         images,\n","#         value_range=(0, 1),\n","#         rows=2,\n","#         cols=2,\n","#     )"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gy_tPHmlUD6w"},"outputs":[],"source":["# Pretrained Model\n","# pretrained_model = keras.applications.EfficientNetV2M(\n","#     include_top=False,\n","#     weights=\"imagenet\",\n","#     input_shape=(1000,1000,3),\n","#     pooling=\"avg\",\n","#     classifier_activation=\"softmax\",\n","#     include_preprocessing=True,\n","# )"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CISm2R-Lirsm"},"outputs":[],"source":["# pretrained_model =  keras_cv.models.YOLOV8Backbone.from_preset(\"yolo_v8_m_backbone_coco\", input_shape=(300,300,3))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cQxu3MyOfeLS"},"outputs":[],"source":["pretrained_model = keras.applications.EfficientNetV2B2(\n","    include_top=False,\n","    weights=\"imagenet\",\n","    input_tensor=None,\n","    input_shape=(300,300,3),\n","    pooling=\"avg\",\n","    classes=1000,\n","    classifier_activation=\"softmax\",\n","    include_preprocessing=False,\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ztkayQRFXf9O"},"outputs":[],"source":["pretrained_model.trainable = False\n","\n","model = tf.keras.Sequential()\n","model.add(pretrained_model)\n","# model.add(Conv2D(320, (3,3), padding='valid', activation='relu'))\n","# model.add(Conv2D(160, (3,3), padding='valid', activation='relu'))\n","# model.add(Conv2D(64, (3,3), padding='valid', activation='relu'))\n","# model.add(Conv2D(32, (3,3), padding='valid', activation='relu'))\n","#model.add(Conv2D(16, (3,3), padding='valid', activation='relu'))\n","model.add(layers.Flatten())\n","model.add(layers.BatchNormalization())\n","model.add(layers.Dense(units=1024, activation=\"relu\"))\n","model.add(layers.Dropout(0.1))\n","model.add(layers.Dense(units=512, activation=\"relu\"))\n","model.add(layers.Dropout(0.1))\n","model.add(layers.Dense(units=256, activation=\"relu\"))\n","model.add(layers.Dropout(0.1))\n","model.add(layers.Dense(units=128, activation=\"relu\"))\n","model.add(layers.Dropout(0.1))\n","model.add(layers.Dense(units=64, activation=\"relu\"))\n","model.add(layers.Dense(units=5, activation=\"softmax\"))\n","\n","model.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wEo2kFbXUD1s"},"outputs":[],"source":["if not config.is_submission:\n","    model.compile(\n","        optimizer=keras.optimizers.Adam(),\n","        loss=keras.losses.CategoricalCrossentropy(),\n","        metrics=[\"accuracy\"],\n","    )\n","\n","    early_stopping_cb = tf.keras.callbacks.EarlyStopping(patience=5, restore_best_weights=True)\n","    checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(\"Ovarian_cancer.h5\", save_best_only=True)\n","\n","    history = model.fit(\n","        train_ds,\n","        epochs=config.epochs,\n","        validation_data=val_ds,\n","        #class_weight=class_weights,\n","        callbacks=[early_stopping_cb,checkpoint_cb],\n","        use_multiprocessing=False,\n","    )"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tSMtMNdeUDzO"},"outputs":[],"source":["# from numba import cuda\n","# device = cuda.get_current_device()\n","# device.reset()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"28rt9VmDctwT"},"outputs":[],"source":["# class Config:\n","#     is_submission = True\n","\n","#     train_csv_path = \"/content/drive/MyDrive/train.csv\"\n","#     train_data_paths = \"/content/drive/MyDrive/Training_files\"\n","#     batch_size = 16\n","#     epochs = 50\n","\n","#     test_csv_path = \"/content/drive/MyDrive/test.csv\"\n","#     test_data_paths = \"/content/drive/MyDrive/Testing_files\"\n","\n","# config = Config()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2P3ha_8jk8yC"},"outputs":[],"source":["# if config.is_submission:\n","#     df = pd.read_csv(config.test_csv_path)\n","#     df[\"image_path\"] = df[\"image_id\"].apply(lambda x: f\"{config.test_data_paths}/{x}_thumbnail.png\")\n","\n","#     # Load the model weights\n","#     model.load_weights(\"/content/drive/MyDrive/Ovarian_cancer.h5\")\n","\n","#     # Load the id to name dictionary\n","#     with open(\"/content/id_to_name.pkl\", \"rb\") as f:\n","#         id_to_name = pickle.load(f)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"whkeE6E-k8ul"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-rm58A9zk8qo"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"cMurpGsfyj6J"},"source":["# Transformer"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nqot36xy8QTS"},"outputs":[],"source":["from google.colab import drive\n","drive.mount(\"/content/drive\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Fj4tkz0l8QQn"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import tensorflow as tf\n","from keras import Model\n","from keras.layers import Layer, Embedding, LayerNormalization, Dense, MultiHeadAttention, Flatten, Add\n","from tensorflow import keras\n","import seaborn as sns\n","import pickle\n","import os\n","\n","os.environ[\"KERAS_BACKEND\"] = \"jax\"\n","\n","sns.set(style=\"whitegrid\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Tx8FHOpwynD8"},"outputs":[],"source":["class Config:\n","    is_submission = False\n","\n","    train_csv_path = \"/content/drive/MyDrive/train.csv\"\n","    train_data_paths = \"/content/drive/MyDrive/Training_files\"\n","    batch_size = 8\n","\n","    test_csv_path = \"/content/drive/MyDrive/test.csv\"\n","    test_data_paths = \"/content/drive/MyDrive/Testing_files\"\n","\n","config = Config()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cyb8k87QynB3"},"outputs":[],"source":["df = pd.read_csv(\"/content/drive/MyDrive/train.csv\")\n","\n","df = df[df[\"is_tma\"] == False]\n","\n","num_rows = df.shape[0]\n","num_unique_images = df['image_id'].nunique()\n","num_unique_labels = df['label'].nunique()\n","unique_labels = df['label'].unique()\n","\n","print(f\"{num_rows=}\")\n","print(f\"{num_unique_images=}\")\n","print(f\"{num_unique_labels=}\")\n","print(f\"{unique_labels=}\")\n","\n","plt.figure(figsize=(10, 6))\n","sns.countplot(data=df, x='label', order=df['label'].value_counts().index)\n","plt.title('Distribution of Target Classes')\n","plt.xlabel('Label')\n","plt.ylabel('Count')\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"k5McG2iyznrc"},"outputs":[],"source":["df.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"08axtvxBznpS"},"outputs":[],"source":["df.describe()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mF9yak9Pym_0"},"outputs":[],"source":["def read_image(path):\n","    file = tf.io.read_file(path)\n","    image = tf.io.decode_png(file, 0)\n","    image = tf.image.resize(image, (500, 300), antialias=True)\n","    image = tf.image.per_image_standardization(image)\n","    image = tf.image.convert_image_dtype(image, tf.float32)\n","    return image"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LC5Gul2Aym9W"},"outputs":[],"source":["my_img = read_image(\"/content/drive/MyDrive/Training_files/10077_thumbnail.png\")\n","my_img.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3CU9b2Et0gzQ"},"outputs":[],"source":["patches = tf.image.extract_patches(\n","                        images=my_img[tf.newaxis,...],\n","                        sizes=[1, 21, 21, 1],\n","                        strides=[1, 21, 21, 1],\n","                        rates=[1, 2, 2, 1],\n","                        padding=\"VALID\"\n","                    )"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9NzUpvo60gxK"},"outputs":[],"source":["patches.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"juS7R4qi0gvH"},"outputs":[],"source":["plt.figure(figsize=(10,10))\n","plt.imshow(my_img)\n","plt.axis(\"off\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"C320mE-F-eI-"},"outputs":[],"source":["# Perform one-hot encoding of the 'label' column and explicitly convert to integer type\n","df_one_hot = pd.get_dummies(df[\"label\"], prefix=\"label\").astype(int)\n","\n","# Concatenate the original DataFrame with the one-hot encoded labels\n","train_df = pd.concat([df[\"image_id\"], df_one_hot], axis=1)\n","\n","# Get the thumbnail image paths\n","train_df[\"train_image_path\"] = train_df[\"image_id\"].apply(lambda x: f\"{config.train_data_paths}/{x}_thumbnail.png\")\n","\n","train_image_paths = train_df[\"train_image_path\"].values\n","labels = train_df[[col for col in train_df.columns if col.startswith(\"label_\")]].values\n","\n","label_names = [col for col in train_df.columns if col.startswith(\"label_\")]\n","name_to_id = {key.replace(\"label_\", \"\"):value for value,key in enumerate(label_names)}\n","id_to_name = {key:value for value, key in name_to_id.items()}\n","\n","# Save to dictionary to disk\n","with open(\"id_to_name.pkl\", \"wb\") as f:\n","    pickle.dump(id_to_name, f)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jVAk8_su8XJM"},"outputs":[],"source":["class PatchEncoder(Layer):\n","    def __init__(self, N_PATCHES, HIDDEN_SIZE):\n","        super(PatchEncoder, self).__init__(name = \"patchencoder\")\n","\n","        self.linear_projection = Dense(HIDDEN_SIZE)\n","        self.positional_embedding = Embedding(N_PATCHES, HIDDEN_SIZE)\n","        self.N_PATCHES = N_PATCHES\n","\n","    def call(self, x_train):\n","\n","        patches = tf.image.extract_patches(\n","                                images=x_train,\n","                                sizes=[1, 21, 21, 1],\n","                                strides=[1, 21, 21, 1],\n","                                rates=[1, 2, 2, 1],\n","                                padding=\"VALID\"\n","                            )\n","\n","        patches = tf.reshape(patches, (tf.shape(patches)[0], -1, 1323))\n","        embedding_input = tf.range(start=0, limit=self.N_PATCHES, delta=1)\n","        output = self.linear_projection(patches) + self.positional_embedding(embedding_input)\n","\n","        return output"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2d-6FY_X8XFy"},"outputs":[],"source":["class TransformerEncoder(Layer):\n","    def __init__(self, N_HEADS, HIDDEN_SIZE):\n","        super(TransformerEncoder, self).__init__(name = \"transformerencoder\")\n","\n","        self.layer_norm_1 = LayerNormalization()\n","        self.layer_norm_2 = LayerNormalization()\n","\n","        self.multi_head_attention = MultiHeadAttention(N_HEADS, HIDDEN_SIZE)\n","\n","        self.dense_1 = Dense(HIDDEN_SIZE, activation=tf.nn.gelu)\n","        self.dense_2 = Dense(HIDDEN_SIZE, activation=tf.nn.gelu)\n","\n","        def call(self, input):\n","            x_1 = self.layer_norm_1(input)\n","            x_1 = self.multi_head_attention(x_1, x_1)\n","\n","            x_1 = Add()([x_1, input])\n","\n","            x_2 = self.layer_norm_2(x_1)\n","            x_2 = self.dense_1(x_2)\n","            x_2 = self.dence_2(x_2)\n","\n","            output = Add()([x_2, x_1])\n","\n","            return output"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"l4AASqlV8XDn"},"outputs":[],"source":["class VIT(Model):\n","    def __init__(self, N_HEADS, HIDDEN_SIZE, N_PATCHES, N_LAYERS, N_DENSE, N_CLASSES):\n","        super(VIT, self).__init__(name = \"visiontransformer\")\n","\n","        self.patch_enc = PatchEncoder(N_PATCHES, HIDDEN_SIZE)\n","        self.transform_encoders = [TransformerEncoder(N_HEADS, HIDDEN_SIZE) for _ in range(N_LAYERS)]\n","        self.N_LAYERS = N_LAYERS\n","        self.dense_1 = Dense(N_DENSE, tf.nn.gelu)\n","        self.dense_2 = Dense(N_DENSE, tf.nn.gelu)\n","        self.dense_3 = Dense(N_DENSE, tf.nn.gelu)\n","        self.dense_4 = Dense(N_CLASSES, tf.nn.softmax)\n","\n","    def call(self, input, training=True):\n","        x = self.patch_enc(input)\n","\n","        for i in range(self.N_LAYERS):\n","            x = self.transform_encoders[i](x)\n","\n","        x = Flatten()(x)\n","        x = self.dense_1(x)\n","        x = self.dense_2(x)\n","        x = self.dense_3(x)\n","        x = self.dense_4(x)\n","\n","        return x"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bkiYvcWw8XBS"},"outputs":[],"source":["x = (tf.data.Dataset.from_tensor_slices(train_image_paths).map(read_image, num_parallel_calls=tf.data.AUTOTUNE, deterministic=True)\n","                                                          #.cache(\"Cached_data_x\")\n","                                                          .prefetch(buffer_size=tf.data.AUTOTUNE)\n",")\n","\n","y = tf.data.Dataset.from_tensor_slices(labels)\n","\n","# Zip the x and y together\n","ds = tf.data.Dataset.zip((x, y))\n","\n","ds_final = (\n","    ds\n","    .shuffle(buffer_size=200)\n","    #.cache(\"Cached_data_ds\")\n","    .prefetch(buffer_size=tf.data.AUTOTUNE)\n",")\n","# Create the training and validation splits\n","val_ds = (\n","    ds_final\n","    .take(100)\n","    .shuffle(100)\n","    .batch(config.batch_size)\n","    #.cache(\"Cached_data_val_ds\")\n","    .prefetch(tf.data.AUTOTUNE)\n",")\n","\n","train_ds = (\n","    ds_final\n","    .shuffle(100)\n","    .batch(config.batch_size)\n","    #.cache(\"Cached_data_train_ds\")\n","    .prefetch(tf.data.AUTOTUNE)\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"f9C1c8dt4nP1"},"outputs":[],"source":["vit_model = VIT(N_HEADS=5, HIDDEN_SIZE=1323, N_PATCHES=286, N_LAYERS=3, N_DENSE=512, N_CLASSES=5)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"D6GBVmhA4nNY"},"outputs":[],"source":["lr_schedule = keras.optimizers.schedules.ExponentialDecay(\n","    initial_learning_rate=1e-2,\n","    decay_steps=100,\n","    decay_rate=0.9)\n","\n","mod_opti = tf.keras.optimizers.Adam(\n","    learning_rate=1e-3,\n","    beta_1=0.9,\n","    beta_2=0.999,\n","    epsilon=1e-7,\n","    amsgrad=False,\n","    weight_decay=None,\n","    clipnorm=None,\n","    clipvalue=None,\n","    global_clipnorm=None,\n","    use_ema=True,\n","    ema_momentum=0.99,\n","    ema_overwrite_frequency=None,\n","    jit_compile=True,\n","    name='Adam',\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fjHihimk_Io9"},"outputs":[],"source":["mod_loss = tf.keras.losses.CategoricalCrossentropy(\n","    from_logits=False,\n","    label_smoothing=0.0,\n","    axis=-1,\n","    name='categorical_crossentropy'\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fKbW34bb_K2C"},"outputs":[],"source":["mod_metrics = [\"accuracy\"]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KUmtArTR_LyE"},"outputs":[],"source":["vit_model.compile(\n","    optimizer=mod_opti,\n","    loss=mod_loss,\n","    metrics=mod_metrics,\n","    loss_weights=None,\n","    weighted_metrics=None,\n","    run_eagerly=None,\n","    steps_per_execution=None,\n","    jit_compile=True,\n","    pss_evaluation_shards=0,\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"h25kcOQH_LhL"},"outputs":[],"source":["history = vit_model.fit(\n","    train_ds,\n","    #batch_size=64,\n","    epochs=10,\n","    verbose=1,\n","    #callbacks=[early_stopping_cb, checkpoint_cb],\n","    #validation_split=0.1,\n","    validation_data=val_ds,\n","    shuffle=True,\n","    class_weight=None,\n","    sample_weight=None,\n","    initial_epoch=0,\n","    steps_per_epoch=6,\n","    validation_steps=None,\n","    validation_batch_size=None,\n","    validation_freq=1,\n","    max_queue_size=10,\n","    workers=1,\n","    use_multiprocessing=True\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2OdiIJKS9Lh_"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2iWx2s-f9Lfh"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aENiPCroOtqZ"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Qi8LK6gXOtoK"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":["zF3DoHOh9Soo"],"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
