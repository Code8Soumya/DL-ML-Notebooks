{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yn01q-Xx61T6"
      },
      "source": [
        "# Lemmetization and Semmetization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hOCfAb_nr41V"
      },
      "outputs": [],
      "source": [
        "import nltk   # Natural Language Toolkit\n",
        "nltk.download(\"punkt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MY_AA26HssnK"
      },
      "outputs": [],
      "source": [
        "paragraph = \"\"\"I have three visions for India. In 3000 years of our history, people from all over\n",
        "               the world have come and invaded us, captured our lands, conquered our minds.\n",
        "               From Alexander onwards, the Greeks, the Turks, the Moguls, the Portuguese, the British,\n",
        "               the French, the Dutch, all of them came and looted us, took over what was ours.\n",
        "               Yet we have not done this to any other nation. We have not conquered anyone.\n",
        "               We have not grabbed their land, their culture,\n",
        "               their history and tried to enforce our way of life on them.\n",
        "               Why? Because we respect the freedom of others.That is why my\n",
        "               first vision is that of freedom. I believe that India got its first vision of\n",
        "               this in 1857, when we started the War of Independence. It is this freedom that\n",
        "               we must protect and nurture and build on. If we are not free, no one will respect us.\n",
        "               My second vision for India’s development. For fifty years we have been a developing nation.\n",
        "               It is time we see ourselves as a developed nation. We are among the top 5 nations of the world\n",
        "               in terms of GDP. We have a 10 percent growth rate in most areas. Our poverty levels are falling.\n",
        "               Our achievements are being globally recognised today. Yet we lack the self-confidence to\n",
        "               see ourselves as a developed nation, self-reliant and self-assured. Isn’t this incorrect?\n",
        "               I have a third vision. India must stand up to the world. Because I believe that unless India\n",
        "               stands up to the world, no one will respect us. Only strength respects strength. We must be\n",
        "               strong not only as a military power but also as an economic power. Both must go hand-in-hand.\n",
        "               My good fortune was to have worked with three great minds. Dr. Vikram Sarabhai of the Dept. of\n",
        "               space, Professor Satish Dhawan, who succeeded him and Dr. Brahm Prakash, father of nuclear material.\n",
        "               I was lucky to have worked with all three of them closely and consider this the great opportunity of my life.\n",
        "               I see four milestones in my career\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JRK14D1XtQNc"
      },
      "outputs": [],
      "source": [
        "sentences = nltk.sent_tokenize(paragraph)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eWhN0MavuBu2"
      },
      "outputs": [],
      "source": [
        "sentences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FRviLvk2uFJ4"
      },
      "outputs": [],
      "source": [
        "len(sentences)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rg_5hY8jvafA"
      },
      "outputs": [],
      "source": [
        "words = nltk.word_tokenize(paragraph)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2w9NB6cjvos8"
      },
      "outputs": [],
      "source": [
        "words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FRMfhR4Kvqvs"
      },
      "outputs": [],
      "source": [
        "from nltk.stem import PorterStemmer\n",
        "nltk.download(\"stopwords\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vXa-K-yN3h3h"
      },
      "outputs": [],
      "source": [
        "from nltk.corpus import stopwords\n",
        "stopwords.words(\"english\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cq0L4X0T4PTI"
      },
      "outputs": [],
      "source": [
        "stemmer = PorterStemmer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wuZLX40h5yiG"
      },
      "outputs": [],
      "source": [
        "sentences = nltk.sent_tokenize(paragraph)\n",
        "\n",
        "for i in range(len(sentences)):\n",
        "  words = nltk.word_tokenize(sentences[i])\n",
        "  words = [stemmer.stem(word) for word in words if word not in stopwords.words(\"english\")]\n",
        "  sentences[i] = \" \".join(words)\n",
        "\n",
        "sentences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ad7d2T2y7DxR"
      },
      "outputs": [],
      "source": [
        "from nltk.stem import WordNetLemmatizer\n",
        "nltk.download('wordnet')\n",
        "lemmatizer = WordNetLemmatizer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r6r_hvGm78a0"
      },
      "outputs": [],
      "source": [
        "sentences = nltk.sent_tokenize(paragraph)\n",
        "\n",
        "for i in range(len(sentences)):\n",
        "  words = nltk.word_tokenize(sentences[i])\n",
        "  words = [lemmatizer.lemmatize(word) for word in words if word not in stopwords.words(\"english\")]\n",
        "  sentences[i] = \" \".join(words)\n",
        "\n",
        "sentences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7GK_-HTC8U3e"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xLyXO4cdh6ro"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lz7kwqua7Q65"
      },
      "source": [
        "# Vectorizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8kN3wgUqeWHu"
      },
      "outputs": [],
      "source": [
        "import nltk   # Natural Language Toolkit\n",
        "nltk.download(\"punkt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z1_2h4Dh7i1N"
      },
      "outputs": [],
      "source": [
        "paragraph = \"\"\"I have three visions for India. In 3000 years of our history, people from all over\n",
        "               the world have come and invaded us, captured our lands, conquered our minds.\n",
        "               From Alexander onwards, the Greeks, the Turks, the Moguls, the Portuguese, the British,\n",
        "               the French, the Dutch, all of them came and looted us, took over what was ours.\n",
        "               Yet we have not done this to any other nation. We have not conquered anyone.\n",
        "               We have not grabbed their land, their culture,\n",
        "               their history and tried to enforce our way of life on them.\n",
        "               Why? Because we respect the freedom of others.That is why my\n",
        "               first vision is that of freedom. I believe that India got its first vision of\n",
        "               this in 1857, when we started the War of Independence. It is this freedom that\n",
        "               we must protect and nurture and build on. If we are not free, no one will respect us.\n",
        "               My second vision for India’s development. For fifty years we have been a developing nation.\n",
        "               It is time we see ourselves as a developed nation. We are among the top 5 nations of the world\n",
        "               in terms of GDP. We have a 10 percent growth rate in most areas. Our poverty levels are falling.\n",
        "               Our achievements are being globally recognised today. Yet we lack the self-confidence to\n",
        "               see ourselves as a developed nation, self-reliant and self-assured. Isn’t this incorrect?\n",
        "               I have a third vision. India must stand up to the world. Because I believe that unless India\n",
        "               stands up to the world, no one will respect us. Only strength respects strength. We must be\n",
        "               strong not only as a military power but also as an economic power. Both must go hand-in-hand.\n",
        "               My good fortune was to have worked with three great minds. Dr. Vikram Sarabhai of the Dept. of\n",
        "               space, Professor Satish Dhawan, who succeeded him and Dr. Brahm Prakash, father of nuclear material.\n",
        "               I was lucky to have worked with all three of them closely and consider this the great opportunity of my life.\n",
        "               I see four milestones in my career\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OEwOp4-OiEsQ"
      },
      "outputs": [],
      "source": [
        "sentences = nltk.sent_tokenize(paragraph)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q9F2cuzah2fG"
      },
      "outputs": [],
      "source": [
        "nltk.download(\"stopwords\")\n",
        "from nltk.corpus import stopwords\n",
        "# stopwords.words(\"english\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-AJExJ_YfmH-"
      },
      "outputs": [],
      "source": [
        "from nltk.stem import WordNetLemmatizer\n",
        "nltk.download('wordnet')\n",
        "lemmatizer = WordNetLemmatizer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MiPHDx69hXYY"
      },
      "outputs": [],
      "source": [
        "sentences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CEOji3Xp7tc3"
      },
      "outputs": [],
      "source": [
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9PgoDPwneWFT"
      },
      "outputs": [],
      "source": [
        "corpus = []\n",
        "for i in range(len(sentences)):\n",
        "    sent = re.sub(\"[^a-zA-Z]\", \" \", sentences[i])\n",
        "    sent = sent.lower()\n",
        "    words = nltk.word_tokenize(sent)\n",
        "    words = [lemmatizer.lemmatize(word) for word in words if word not in stopwords.words(\"english\")]\n",
        "    sent = \" \".join(words)\n",
        "    corpus.append(sent)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hna9oCzpgyAw"
      },
      "outputs": [],
      "source": [
        "corpus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hfHIMjpAhdMc"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CVge2uzvi3xP"
      },
      "outputs": [],
      "source": [
        "vectorizer = CountVectorizer(max_features=1500)\n",
        "X = vectorizer.fit_transform(corpus).toarray()\n",
        "X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o0_lFo0wkgCE"
      },
      "outputs": [],
      "source": [
        "X.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BPMzVUjhkro_"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v68jgvW4mtIN"
      },
      "outputs": [],
      "source": [
        "vectorizer = TfidfVectorizer(max_features=1500)\n",
        "X = vectorizer.fit_transform(corpus).toarray()\n",
        "X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jUfT00V9m2Aw"
      },
      "outputs": [],
      "source": [
        "X.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Re8bjbEu78TF"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v21j3ssj8Tdi"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r4e7jYNP79Nl"
      },
      "source": [
        "# Project_Stock_sentiment_analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bpD0ufqOm5h9"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U_XUdvd18XAJ"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2iCXrImo8jz-"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"/content/drive/MyDrive/Data.csv\", encoding=\"ISO-8859-1\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z1Cqz9nv9Gjb"
      },
      "outputs": [],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RtLGHYK68kXs"
      },
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pMKsbSkUeGUN"
      },
      "outputs": [],
      "source": [
        "df.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-xMzIv8xhGfX"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "nltk.download(\"punkt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wlFMSmMeibUJ"
      },
      "outputs": [],
      "source": [
        "nltk.download(\"stopwords\")\n",
        "from nltk.corpus import stopwords"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l3Wv80M0ibRf"
      },
      "outputs": [],
      "source": [
        "from nltk.stem import WordNetLemmatizer\n",
        "nltk.download('wordnet')\n",
        "lemmatizer = WordNetLemmatizer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xWuA7cmpjc3q"
      },
      "outputs": [],
      "source": [
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "evcVzJR09PHq"
      },
      "outputs": [],
      "source": [
        "df[\"Headlines\"] = df[df.columns[2]].str.cat([df[c] for c in df.columns[3:]], sep=\" \")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DyIPrysQhgSp"
      },
      "outputs": [],
      "source": [
        "for i in range(len(df[\"Headlines\"])):\n",
        "    headline = re.sub(\"[^a-zA-Z]\", \" \", str(df[\"Headlines\"][i]))\n",
        "    headline = headline.lower()\n",
        "    words = nltk.word_tokenize(headline)\n",
        "    words = [lemmatizer.lemmatize(word) for word in words if word not in stopwords.words(\"english\")]\n",
        "    headline = \" \".join(words)\n",
        "    df[\"Headlines\"][i] = headline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lB8OjlGC9PDZ"
      },
      "outputs": [],
      "source": [
        "df_final = df[[\"Label\", \"Headlines\"]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "afLeaQ0w9Onh"
      },
      "outputs": [],
      "source": [
        "df_final.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TWJ5nAXO9OlK"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.ensemble import RandomForestClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e9NIMTcC9Oiz"
      },
      "outputs": [],
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(np.array(df_final[\"Headlines\"]), np.array(df_final[\"Label\"]),\n",
        "                                                    test_size=0.1, random_state=42, shuffle=True,\n",
        "                                                )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9vHUApp_mMe8"
      },
      "outputs": [],
      "source": [
        "x_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l4UWbw_EmMdH"
      },
      "outputs": [],
      "source": [
        "y_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zwL69OjsmMar"
      },
      "outputs": [],
      "source": [
        "vectorizer = TfidfVectorizer(max_features=2000, ngram_range=(2,2))\n",
        "X_train = vectorizer.fit_transform(x_train).toarray()\n",
        "X_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wcNVyoHD9Oge"
      },
      "outputs": [],
      "source": [
        "X_test = vectorizer.transform(x_test).toarray()\n",
        "X_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "381smVR8pGCi"
      },
      "outputs": [],
      "source": [
        "clf = RandomForestClassifier(n_estimators=500, criterion=\"entropy\", n_jobs=-1, max_depth=4, verbose=1)\n",
        "clf.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B1AoUaHBt8R0"
      },
      "outputs": [],
      "source": [
        "y_pred = clf.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-dqhYP0QpGAg"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cUABodB9pF-C"
      },
      "outputs": [],
      "source": [
        "print(accuracy_score(y_test, y_pred))\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sPPPu6ASuVY-"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hXdbYAInuVWf"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_WgXRCalCtrB"
      },
      "source": [
        "# Keras_Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uIa9urxECxvx"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from keras.preprocessing.text import Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uDUdSGcBCxsV"
      },
      "outputs": [],
      "source": [
        "docs = [\n",
        "        'recurrent neural network',\n",
        "\t\t'neural network',\n",
        "\t\t'artificial neural',\n",
        "\t\t'connections between nodes',\n",
        "\t\t'can create a cycle',\n",
        "\t\t'allowing output',\n",
        "\t\t'some nodes to affect subsequent',\n",
        "\t\t'exhibit temporal',\n",
        "\t\t'dynamic behavior',\n",
        "\t\t'type of Neural Network',\n",
        "        'affect subsequent',\n",
        "    ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v3dcselepF7t"
      },
      "outputs": [],
      "source": [
        "tokenizer = Tokenizer(oov_token = '<nothing>')\n",
        "tokenizer.fit_on_texts(docs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UqanimuHygyW"
      },
      "outputs": [],
      "source": [
        "tokenizer.word_index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1syS8_4KCw8V"
      },
      "outputs": [],
      "source": [
        "tokenizer.word_counts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mDvv5QcmCw6L"
      },
      "outputs": [],
      "source": [
        "sequences = tokenizer.texts_to_sequences(docs)\n",
        "sequences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "abMCWai1EDjj"
      },
      "outputs": [],
      "source": [
        "from keras.utils import pad_sequences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6fhO_nDzEDhQ"
      },
      "outputs": [],
      "source": [
        "sequences = pad_sequences(sequences,padding='post')\n",
        "sequences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zhheHQ2HEDW7"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sopNVoh2EDSw"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZORADbiDE9YT"
      },
      "source": [
        "# Sentiment_analysis_RNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mbxSFCrrEDQX"
      },
      "outputs": [],
      "source": [
        "from keras.datasets import imdb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M8Fp9HwSEDOP"
      },
      "outputs": [],
      "source": [
        "(x_train,y_train),(x_test,y_test) = imdb.load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y_wh0AqZEDL5"
      },
      "outputs": [],
      "source": [
        "x_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PV6aXcLzEDJ3"
      },
      "outputs": [],
      "source": [
        "y_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FRgx5JpJEDDX"
      },
      "outputs": [],
      "source": [
        "x_train[:2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3XuwzMJrFX2s"
      },
      "outputs": [],
      "source": [
        "y_train[:2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YjiqqgYVGhK4"
      },
      "outputs": [],
      "source": [
        "len(x_train[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zsfqv-S8FX0X"
      },
      "outputs": [],
      "source": [
        "from keras.utils import pad_sequences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "39wSrGpaFXx5"
      },
      "outputs": [],
      "source": [
        "x_train = pad_sequences(x_train,padding='post', maxlen=50)\n",
        "X_test = pad_sequences(x_test,padding='post', maxlen=50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UMVo_ZFyFXvu"
      },
      "outputs": [],
      "source": [
        "len(x_train[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6eyq-eKkGs0d"
      },
      "outputs": [],
      "source": [
        "from keras import Sequential\n",
        "from keras.layers import Dense,SimpleRNN,Embedding,Flatten\n",
        "\n",
        "model = Sequential()\n",
        "model.add(SimpleRNN(32,input_shape=(50,1),return_sequences=False))\n",
        "model.add(Dense(1,activation='sigmoid'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Py_Zec1GsyL"
      },
      "outputs": [],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O7rAhnBcGsv3"
      },
      "outputs": [],
      "source": [
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "l9HKX2QsGstU"
      },
      "outputs": [],
      "source": [
        "model.fit(x_train, y_train, epochs=10, validation_data = (x_test, y_test), verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RFT9cOKgGsq6"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7ZvERR1GEDAh"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lgJEyGVpusUD"
      },
      "source": [
        "# Simple_RNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VXRdi1HoKE-D"
      },
      "outputs": [],
      "source": [
        "from keras import Sequential\n",
        "from keras.layers import Dense, SimpleRNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ky11xNrKuu7r"
      },
      "outputs": [],
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(SimpleRNN(3, input_shape=(4, 5)))\n",
        "model.add(Dense(1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ixPcnW4Kuu5k"
      },
      "outputs": [],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5jaszYpKuuwf"
      },
      "outputs": [],
      "source": [
        "num = 0\n",
        "print(model.get_weights()[num].shape)\n",
        "print(model.get_weights()[num])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FhBvsCM4uur2"
      },
      "outputs": [],
      "source": [
        "num = 1\n",
        "print(model.get_weights()[num].shape)\n",
        "print(model.get_weights()[num])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KpUCUBRLuupR"
      },
      "outputs": [],
      "source": [
        "num = 2\n",
        "print(model.get_weights()[num].shape)\n",
        "print(model.get_weights()[num])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G6hMWbxpKE7_"
      },
      "outputs": [],
      "source": [
        "num = 3\n",
        "print(model.get_weights()[num].shape)\n",
        "print(model.get_weights()[num])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6iJ2ikC4KE5d"
      },
      "outputs": [],
      "source": [
        "num = 4\n",
        "print(model.get_weights()[num].shape)\n",
        "print(model.get_weights()[num])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WSXpP_dfxBye"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YjbzYgIExBwA"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DIP1QsH7zBKF"
      },
      "source": [
        "# Integer_encoding_simplernn_imdb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fSqKkSpzy_6a"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "docs = ['go india',\n",
        "\t\t'india india',\n",
        "\t\t'hip hip hurray',\n",
        "\t\t'jeetega bhai jeetega india jeetega',\n",
        "\t\t'bharat mata ki jai',\n",
        "\t\t'kohli kohli',\n",
        "\t\t'sachin sachin',\n",
        "\t\t'dhoni dhoni',\n",
        "\t\t'modi ji ki jai',\n",
        "\t\t'inquilab zindabad']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QAdU8gPgy_3E"
      },
      "outputs": [],
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "tokenizer = Tokenizer(oov_token='<nothing>')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2CytEU7Cy_04"
      },
      "outputs": [],
      "source": [
        "tokenizer.fit_on_texts(docs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X-TBlSnFy_yh"
      },
      "outputs": [],
      "source": [
        "tokenizer.word_index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cXGvbErhy_wS"
      },
      "outputs": [],
      "source": [
        "tokenizer.word_counts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WMa_ybply_t_"
      },
      "outputs": [],
      "source": [
        "tokenizer.document_count"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "re672jaTy_ru"
      },
      "outputs": [],
      "source": [
        "sequences = tokenizer.texts_to_sequences(docs)\n",
        "sequences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rae-OhxOy_pg"
      },
      "outputs": [],
      "source": [
        "from keras.utils import pad_sequences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-XlSoM40y_nU"
      },
      "outputs": [],
      "source": [
        "sequences = pad_sequences(sequences, padding='post')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p7pSf8hqy_lK"
      },
      "outputs": [],
      "source": [
        "sequences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QqwgINRey_i5"
      },
      "outputs": [],
      "source": [
        "from keras.datasets import imdb\n",
        "from keras import Sequential\n",
        "from keras.layers import Dense,SimpleRNN,Flatten"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "686qo9Pjy_gh"
      },
      "outputs": [],
      "source": [
        "(X_train,y_train),(X_test,y_test) = imdb.load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F4X4PauzxBtG"
      },
      "outputs": [],
      "source": [
        "X_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5unHJa6G0RTJ"
      },
      "outputs": [],
      "source": [
        "X_train[:2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wcBaeTt90RPx"
      },
      "outputs": [],
      "source": [
        "X_train = pad_sequences(X_train,padding='post',maxlen=200)\n",
        "X_test = pad_sequences(X_test,padding='post',maxlen=200)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vPwjIHbw0RNx"
      },
      "outputs": [],
      "source": [
        "X_train[:2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-BfqBr4q0RLv"
      },
      "outputs": [],
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(SimpleRNN(32,input_shape=(200,1),return_sequences=False))\n",
        "model.add(Dense(1,activation='sigmoid'))\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ez8UnmbC0RJl"
      },
      "outputs": [],
      "source": [
        "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
        "model.fit(X_train,y_train,epochs=2,validation_data=(X_test,y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6XBHNv560myJ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tmmk4Joz0mwC"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RNhdgc1c5Jm6"
      },
      "source": [
        "# Embedding_simplernn_imdb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "849hFO_V0mty"
      },
      "outputs": [],
      "source": [
        "docs = ['go india',\n",
        "\t\t'india india',\n",
        "\t\t'hip hip hurray',\n",
        "\t\t'jeetega bhai jeetega india jeetega',\n",
        "\t\t'bharat mata ki jai',\n",
        "\t\t'kohli kohli',\n",
        "\t\t'sachin sachin',\n",
        "\t\t'dhoni dhoni',\n",
        "\t\t'modi ji ki jai',\n",
        "\t\t'inquilab zindabad']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Was6TyID0mrg"
      },
      "outputs": [],
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "tokenizer = Tokenizer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PATQciSI0mpC"
      },
      "outputs": [],
      "source": [
        "tokenizer.fit_on_texts(docs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H64PyDLz5Vk3"
      },
      "outputs": [],
      "source": [
        "sequences = tokenizer.texts_to_sequences(docs)\n",
        "sequences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4yzL3cDj5ViG"
      },
      "outputs": [],
      "source": [
        "from keras.utils import pad_sequences\n",
        "\n",
        "sequences = pad_sequences(sequences,padding='post')\n",
        "sequences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8g5SD_fr5Vfi"
      },
      "outputs": [],
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(17,output_dim=2,input_length=5))\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "20xcq13y5Vdy"
      },
      "outputs": [],
      "source": [
        "model.compile('adam','accuracy')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r0C2ncB55Va6"
      },
      "outputs": [],
      "source": [
        "pred = model.predict(sequences)\n",
        "print(pred.shape)\n",
        "print(pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w8hKBpoD5VYe"
      },
      "outputs": [],
      "source": [
        "from keras.datasets import imdb\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.utils import pad_sequences\n",
        "from keras import Sequential\n",
        "from keras.layers import Dense,SimpleRNN,Embedding,Flatten"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rYUZWOEP5VTL"
      },
      "outputs": [],
      "source": [
        "(X_train,y_train),(X_test,y_test) = imdb.load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cwoZv2CP5VQc"
      },
      "outputs": [],
      "source": [
        "X_train = pad_sequences(X_train,padding='post',maxlen=100)\n",
        "X_test = pad_sequences(X_test,padding='post',maxlen=100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kxy5P7o98wHo"
      },
      "outputs": [],
      "source": [
        "X_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n1dKPSwc8v9E"
      },
      "outputs": [],
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(10000, output_dim=3,input_length=100))\n",
        "model.add(SimpleRNN(50,return_sequences=False))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ro9Kh5308v6J"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "history = model.fit(X_train,y_train,epochs=5,validation_data=(X_test,y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UE-LzV3u9R21"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4XKAYxQD9R06"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sG0pVzj89RyG"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EAWucAox8v06"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8OHvBWVdD2ag"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tbdRQ-lHD2Wm"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "yn01q-Xx61T6",
        "Lz7kwqua7Q65",
        "r4e7jYNP79Nl",
        "_WgXRCalCtrB",
        "ZORADbiDE9YT",
        "lgJEyGVpusUD",
        "DIP1QsH7zBKF",
        "RNhdgc1c5Jm6"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
